{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = 43\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = pd.read_csv(open('clean_positive_train.csv','r'), encoding='utf-8', engine='c')\n",
    "df_neg = pd.read_csv(open('clean_negative_train.csv','r'), encoding='utf-8', engine='c')\n",
    "\n",
    "df_pos['text'] = df_pos['text'].astype(str)\n",
    "df_pos['parent_text'] = df_pos['parent_text'].astype(str)\n",
    "\n",
    "df_neg['text'] = df_neg['text'].astype(str)\n",
    "df_neg['parent_text'] = df_neg['parent_text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>parent_score</th>\n",
       "      <th>parent_ups</th>\n",
       "      <th>parent_controversiality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>99999.0</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>198.155082</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.990770</td>\n",
       "      <td>368.973070</td>\n",
       "      <td>0.00064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>256.334734</td>\n",
       "      <td>0.004472</td>\n",
       "      <td>0.095629</td>\n",
       "      <td>535.679712</td>\n",
       "      <td>0.02529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8907.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>417.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5488.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9531.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         score           ups  controversiality  parent_score    parent_ups  \\\n",
       "count  99999.0  99999.000000      99999.000000  99999.000000  99999.000000   \n",
       "mean       1.0    198.155082          0.000020      0.990770    368.973070   \n",
       "std        0.0    256.334734          0.004472      0.095629    535.679712   \n",
       "min        1.0     66.000000          0.000000      0.000000  -8907.000000   \n",
       "25%        1.0     83.000000          0.000000      1.000000     84.000000   \n",
       "50%        1.0    116.000000          0.000000      1.000000    184.000000   \n",
       "75%        1.0    200.000000          0.000000      1.000000    417.000000   \n",
       "max        1.0   5488.000000          1.000000      1.000000   9531.000000   \n",
       "\n",
       "       parent_controversiality  \n",
       "count              99999.00000  \n",
       "mean                   0.00064  \n",
       "std                    0.02529  \n",
       "min                    0.00000  \n",
       "25%                    0.00000  \n",
       "50%                    0.00000  \n",
       "75%                    0.00000  \n",
       "max                    1.00000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pos.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>parent_score</th>\n",
       "      <th>parent_ups</th>\n",
       "      <th>parent_controversiality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>99998.0</td>\n",
       "      <td>99998.000000</td>\n",
       "      <td>99998.000000</td>\n",
       "      <td>99998.000000</td>\n",
       "      <td>99998.000000</td>\n",
       "      <td>99998.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-14.583632</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>0.912518</td>\n",
       "      <td>67.440239</td>\n",
       "      <td>0.002720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15.649932</td>\n",
       "      <td>0.038572</td>\n",
       "      <td>0.282541</td>\n",
       "      <td>219.047635</td>\n",
       "      <td>0.052083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1077.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1622.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14776.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         score           ups  controversiality  parent_score    parent_ups  \\\n",
       "count  99998.0  99998.000000      99998.000000  99998.000000  99998.000000   \n",
       "mean       0.0    -14.583632          0.001490      0.912518     67.440239   \n",
       "std        0.0     15.649932          0.038572      0.282541    219.047635   \n",
       "min        0.0  -1077.000000          0.000000      0.000000  -1622.000000   \n",
       "25%        0.0    -15.000000          0.000000      1.000000      6.000000   \n",
       "50%        0.0    -10.000000          0.000000      1.000000     15.000000   \n",
       "75%        0.0     -8.000000          0.000000      1.000000     44.000000   \n",
       "max        0.0     -6.000000          1.000000      1.000000  14776.000000   \n",
       "\n",
       "       parent_controversiality  \n",
       "count             99998.000000  \n",
       "mean                  0.002720  \n",
       "std                   0.052083  \n",
       "min                   0.000000  \n",
       "25%                   0.000000  \n",
       "50%                   0.000000  \n",
       "75%                   0.000000  \n",
       "max                   1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neg.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (189997,)\n",
      "X_test: (10000,)\n",
      "y_train: (189997,)\n",
      "y_test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df_pos, df_neg])\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.dropna(axis=0, inplace=True)\n",
    "df['combined'] = df[['text', 'parent_text']].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "X = df['combined']\n",
    "y = df['score']\n",
    "#X_train, X_test, y_train, y_test = train_test_split(text_data,text_score, test_size = 0.20, random_state = 42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=SEED)\n",
    "\n",
    "# To be sure we don't use indices to predict something\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Токенизируем текст\n",
    "tokenizer = Tokenizer(num_words=10000, lower=True, split=' ', document_count=0)\n",
    "tokenizer.fit_on_texts(X)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#каждое предложение имеет разную длину, и мы хотим каждый раз передавать один и тот же вектор длины в нашу нейронную сеть,\n",
    "#мы дополняем их, добавляя нули в конце каждой последовательности, поэтому каждое из них имеет длину 128 целых чисел.\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(X_train_seq,\n",
    "                                                        value=0,\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=128)\n",
    "\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(X_test_seq,\n",
    "                                                        value=0,\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 128\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data[0]), len(train_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0405 14:16:20.825892 140362287126336 deprecation.py:506] From /home/evgenia/CourseraEnv/env/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0405 14:16:20.862070 140362287126336 deprecation.py:506] From /home/evgenia/CourseraEnv/env/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 4)           868984    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 868,997\n",
      "Trainable params: 868,997\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#делаем нейросеть\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, 4))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(2, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 189997 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "189997/189997 [==============================] - 6s 32us/sample - loss: 0.6867 - acc: 0.5927 - val_loss: 0.6738 - val_acc: 0.6435\n",
      "Epoch 2/40\n",
      "189997/189997 [==============================] - 6s 33us/sample - loss: 0.6587 - acc: 0.6569 - val_loss: 0.6445 - val_acc: 0.6803\n",
      "Epoch 3/40\n",
      "189997/189997 [==============================] - 7s 36us/sample - loss: 0.6307 - acc: 0.6834 - val_loss: 0.6247 - val_acc: 0.6827\n",
      "Epoch 4/40\n",
      "189997/189997 [==============================] - 6s 31us/sample - loss: 0.6112 - acc: 0.6940 - val_loss: 0.6132 - val_acc: 0.6889\n",
      "Epoch 5/40\n",
      "189997/189997 [==============================] - 6s 31us/sample - loss: 0.5982 - acc: 0.6995 - val_loss: 0.6071 - val_acc: 0.6891\n",
      "Epoch 6/40\n",
      "189997/189997 [==============================] - 5s 28us/sample - loss: 0.5893 - acc: 0.7032 - val_loss: 0.6037 - val_acc: 0.6931\n",
      "Epoch 7/40\n",
      "189997/189997 [==============================] - 5s 26us/sample - loss: 0.5829 - acc: 0.7060 - val_loss: 0.6019 - val_acc: 0.6947\n",
      "Epoch 8/40\n",
      "189997/189997 [==============================] - 5s 27us/sample - loss: 0.5784 - acc: 0.7083 - val_loss: 0.6016 - val_acc: 0.6912\n",
      "Epoch 9/40\n",
      "189997/189997 [==============================] - 5s 28us/sample - loss: 0.5750 - acc: 0.7102 - val_loss: 0.6014 - val_acc: 0.6927\n",
      "Epoch 10/40\n",
      "189997/189997 [==============================] - 5s 29us/sample - loss: 0.5724 - acc: 0.7118 - val_loss: 0.6023 - val_acc: 0.6870\n",
      "Epoch 11/40\n",
      "189997/189997 [==============================] - 5s 28us/sample - loss: 0.5700 - acc: 0.7131 - val_loss: 0.6026 - val_acc: 0.6933\n",
      "Epoch 12/40\n",
      "189997/189997 [==============================] - 5s 27us/sample - loss: 0.5683 - acc: 0.7135 - val_loss: 0.6035 - val_acc: 0.6936\n",
      "Epoch 13/40\n",
      "189997/189997 [==============================] - 6s 29us/sample - loss: 0.5667 - acc: 0.7138 - val_loss: 0.6059 - val_acc: 0.6845\n",
      "Epoch 14/40\n",
      "189997/189997 [==============================] - 5s 27us/sample - loss: 0.5654 - acc: 0.7152 - val_loss: 0.6059 - val_acc: 0.6896\n",
      "Epoch 15/40\n",
      "189997/189997 [==============================] - 5s 28us/sample - loss: 0.5643 - acc: 0.7156 - val_loss: 0.6072 - val_acc: 0.6913\n",
      "Epoch 16/40\n",
      "189997/189997 [==============================] - 6s 32us/sample - loss: 0.5636 - acc: 0.7166 - val_loss: 0.6079 - val_acc: 0.6903\n",
      "Epoch 17/40\n",
      "189997/189997 [==============================] - 6s 34us/sample - loss: 0.5626 - acc: 0.7166 - val_loss: 0.6090 - val_acc: 0.6863\n",
      "Epoch 18/40\n",
      "189997/189997 [==============================] - 7s 36us/sample - loss: 0.5619 - acc: 0.7167 - val_loss: 0.6102 - val_acc: 0.6855\n",
      "Epoch 19/40\n",
      "189997/189997 [==============================] - 6s 33us/sample - loss: 0.5612 - acc: 0.7174 - val_loss: 0.6133 - val_acc: 0.6801\n",
      "Epoch 20/40\n",
      "189997/189997 [==============================] - 5s 26us/sample - loss: 0.5609 - acc: 0.7178 - val_loss: 0.6120 - val_acc: 0.6869\n",
      "Epoch 21/40\n",
      "189997/189997 [==============================] - 5s 25us/sample - loss: 0.5604 - acc: 0.7180 - val_loss: 0.6131 - val_acc: 0.6856\n",
      "Epoch 22/40\n",
      "189997/189997 [==============================] - 5s 25us/sample - loss: 0.5600 - acc: 0.7173 - val_loss: 0.6139 - val_acc: 0.6855\n",
      "Epoch 23/40\n",
      "189997/189997 [==============================] - 5s 26us/sample - loss: 0.5595 - acc: 0.7180 - val_loss: 0.6172 - val_acc: 0.6831\n",
      "Epoch 24/40\n",
      "189997/189997 [==============================] - 5s 28us/sample - loss: 0.5592 - acc: 0.7181 - val_loss: 0.6168 - val_acc: 0.6843\n",
      "Epoch 25/40\n",
      "189997/189997 [==============================] - 6s 33us/sample - loss: 0.5590 - acc: 0.7183 - val_loss: 0.6168 - val_acc: 0.6833\n",
      "Epoch 26/40\n",
      "189997/189997 [==============================] - 6s 33us/sample - loss: 0.5586 - acc: 0.7187 - val_loss: 0.6189 - val_acc: 0.6822\n",
      "Epoch 27/40\n",
      "189997/189997 [==============================] - 6s 32us/sample - loss: 0.5584 - acc: 0.7183 - val_loss: 0.6182 - val_acc: 0.6829\n",
      "Epoch 28/40\n",
      "189997/189997 [==============================] - 7s 38us/sample - loss: 0.5581 - acc: 0.7185 - val_loss: 0.6195 - val_acc: 0.6839\n",
      "Epoch 29/40\n",
      "189997/189997 [==============================] - 7s 38us/sample - loss: 0.5579 - acc: 0.7183 - val_loss: 0.6201 - val_acc: 0.6842\n",
      "Epoch 30/40\n",
      "189997/189997 [==============================] - 6s 34us/sample - loss: 0.5577 - acc: 0.7182 - val_loss: 0.6201 - val_acc: 0.6814\n",
      "Epoch 31/40\n",
      "189997/189997 [==============================] - 7s 38us/sample - loss: 0.5576 - acc: 0.7185 - val_loss: 0.6204 - val_acc: 0.6821\n",
      "Epoch 32/40\n",
      "189997/189997 [==============================] - 7s 35us/sample - loss: 0.5575 - acc: 0.7182 - val_loss: 0.6213 - val_acc: 0.6818\n",
      "Epoch 33/40\n",
      "189997/189997 [==============================] - 8s 41us/sample - loss: 0.5573 - acc: 0.7185 - val_loss: 0.6216 - val_acc: 0.6822\n",
      "Epoch 34/40\n",
      "189997/189997 [==============================] - 5s 29us/sample - loss: 0.5572 - acc: 0.7186 - val_loss: 0.6222 - val_acc: 0.6816\n",
      "Epoch 35/40\n",
      "189997/189997 [==============================] - 5s 28us/sample - loss: 0.5571 - acc: 0.7186 - val_loss: 0.6225 - val_acc: 0.6813\n",
      "Epoch 36/40\n",
      "189997/189997 [==============================] - 5s 27us/sample - loss: 0.5570 - acc: 0.7187 - val_loss: 0.6227 - val_acc: 0.6802\n",
      "Epoch 37/40\n",
      "189997/189997 [==============================] - 7s 36us/sample - loss: 0.5569 - acc: 0.7186 - val_loss: 0.6232 - val_acc: 0.6799\n",
      "Epoch 38/40\n",
      "189997/189997 [==============================] - 7s 35us/sample - loss: 0.5567 - acc: 0.7191 - val_loss: 0.6250 - val_acc: 0.6813\n",
      "Epoch 39/40\n",
      "189997/189997 [==============================] - 6s 30us/sample - loss: 0.5568 - acc: 0.7189 - val_loss: 0.6244 - val_acc: 0.6774\n",
      "Epoch 40/40\n",
      "189997/189997 [==============================] - 6s 30us/sample - loss: 0.5567 - acc: 0.7185 - val_loss: 0.6263 - val_acc: 0.6811\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data,\n",
    "                    y_train,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(test_data, y_test),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2500035416432395"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = np.full(y_test.shape, y_train.mean())\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
