{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = pd.read_csv(open('clean_positive_train.csv','r'), encoding='utf-8', engine='c')\n",
    "df_neg = pd.read_csv(open('clean_negative_train.csv','r'), encoding='utf-8', engine='c')\n",
    "\n",
    "df_pos['text'] = df_pos['text'].astype(str)\n",
    "df_pos['parent_text'] = df_pos['parent_text'].astype(str)\n",
    "\n",
    "df_neg['text'] = df_neg['text'].astype(str)\n",
    "df_neg['parent_text'] = df_neg['parent_text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>parent_score</th>\n",
       "      <th>parent_ups</th>\n",
       "      <th>parent_controversiality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>99999.0</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>99999.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>198.155082</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.990770</td>\n",
       "      <td>368.973070</td>\n",
       "      <td>0.00064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>256.334734</td>\n",
       "      <td>0.004472</td>\n",
       "      <td>0.095629</td>\n",
       "      <td>535.679712</td>\n",
       "      <td>0.02529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8907.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>417.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5488.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9531.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         score           ups  controversiality  parent_score    parent_ups  \\\n",
       "count  99999.0  99999.000000      99999.000000  99999.000000  99999.000000   \n",
       "mean       1.0    198.155082          0.000020      0.990770    368.973070   \n",
       "std        0.0    256.334734          0.004472      0.095629    535.679712   \n",
       "min        1.0     66.000000          0.000000      0.000000  -8907.000000   \n",
       "25%        1.0     83.000000          0.000000      1.000000     84.000000   \n",
       "50%        1.0    116.000000          0.000000      1.000000    184.000000   \n",
       "75%        1.0    200.000000          0.000000      1.000000    417.000000   \n",
       "max        1.0   5488.000000          1.000000      1.000000   9531.000000   \n",
       "\n",
       "       parent_controversiality  \n",
       "count              99999.00000  \n",
       "mean                   0.00064  \n",
       "std                    0.02529  \n",
       "min                    0.00000  \n",
       "25%                    0.00000  \n",
       "50%                    0.00000  \n",
       "75%                    0.00000  \n",
       "max                    1.00000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pos.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>parent_score</th>\n",
       "      <th>parent_ups</th>\n",
       "      <th>parent_controversiality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>99998.0</td>\n",
       "      <td>99998.000000</td>\n",
       "      <td>99998.000000</td>\n",
       "      <td>99998.000000</td>\n",
       "      <td>99998.000000</td>\n",
       "      <td>99998.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-14.583632</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>0.912518</td>\n",
       "      <td>67.440239</td>\n",
       "      <td>0.002720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15.649932</td>\n",
       "      <td>0.038572</td>\n",
       "      <td>0.282541</td>\n",
       "      <td>219.047635</td>\n",
       "      <td>0.052083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1077.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1622.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14776.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         score           ups  controversiality  parent_score    parent_ups  \\\n",
       "count  99998.0  99998.000000      99998.000000  99998.000000  99998.000000   \n",
       "mean       0.0    -14.583632          0.001490      0.912518     67.440239   \n",
       "std        0.0     15.649932          0.038572      0.282541    219.047635   \n",
       "min        0.0  -1077.000000          0.000000      0.000000  -1622.000000   \n",
       "25%        0.0    -15.000000          0.000000      1.000000      6.000000   \n",
       "50%        0.0    -10.000000          0.000000      1.000000     15.000000   \n",
       "75%        0.0     -8.000000          0.000000      1.000000     44.000000   \n",
       "max        0.0     -6.000000          1.000000      1.000000  14776.000000   \n",
       "\n",
       "       parent_controversiality  \n",
       "count             99998.000000  \n",
       "mean                  0.002720  \n",
       "std                   0.052083  \n",
       "min                   0.000000  \n",
       "25%                   0.000000  \n",
       "50%                   0.000000  \n",
       "75%                   0.000000  \n",
       "max                   1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neg.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (159997,)\n",
      "X_test: (40000,)\n",
      "y_train: (159997,)\n",
      "y_test: (40000,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df_pos, df_neg])\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.dropna(axis=0, inplace=True)\n",
    "df['combined'] = df[['text', 'parent_text']].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "text_data = df['combined']\n",
    "text_score = df['score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_data,text_score, test_size = 0.20, random_state = 42)\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Токенизируем текст\n",
    "tokenizer = Tokenizer(num_words=10000, lower=True, split=' ', document_count=0)\n",
    "tokenizer.fit_on_texts(text_data)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#каждое предложение имеет разную длину, и мы хотим каждый раз передавать один и тот же вектор длины в нашу нейронную сеть,\n",
    "#мы дополняем их, добавляя нули в конце каждой последовательности, поэтому каждое из них имеет длину 128 целых чисел.\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(X_train_seq,\n",
    "                                                        value=0,\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=128)\n",
    "\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(X_test_seq,\n",
    "                                                        value=0,\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 128\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data[0]), len(train_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0404 21:50:08.030283 139873078146880 deprecation.py:506] From /home/evgenia/CourseraEnv/env/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0404 21:50:08.056196 139873078146880 deprecation.py:506] From /home/evgenia/CourseraEnv/env/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 4)           868984    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 868,997\n",
      "Trainable params: 868,997\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#делаем нейросеть\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, 4))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(2, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159997 samples, validate on 40000 samples\n",
      "Epoch 1/40\n",
      "159997/159997 [==============================] - 6s 39us/sample - loss: 0.6897 - acc: 0.5655 - val_loss: 0.6819 - val_acc: 0.6041\n",
      "Epoch 2/40\n",
      "159997/159997 [==============================] - 6s 35us/sample - loss: 0.6671 - acc: 0.6282 - val_loss: 0.6519 - val_acc: 0.6334\n",
      "Epoch 3/40\n",
      "159997/159997 [==============================] - 4s 27us/sample - loss: 0.6357 - acc: 0.6678 - val_loss: 0.6260 - val_acc: 0.6763\n",
      "Epoch 4/40\n",
      "159997/159997 [==============================] - 4s 28us/sample - loss: 0.6140 - acc: 0.6840 - val_loss: 0.6128 - val_acc: 0.6834\n",
      "Epoch 5/40\n",
      "159997/159997 [==============================] - 5s 32us/sample - loss: 0.6011 - acc: 0.6930 - val_loss: 0.6055 - val_acc: 0.6895\n",
      "Epoch 6/40\n",
      "159997/159997 [==============================] - 5s 33us/sample - loss: 0.5919 - acc: 0.6993 - val_loss: 0.6010 - val_acc: 0.6921\n",
      "Epoch 7/40\n",
      "159997/159997 [==============================] - 5s 33us/sample - loss: 0.5848 - acc: 0.7044 - val_loss: 0.5975 - val_acc: 0.6933\n",
      "Epoch 8/40\n",
      "159997/159997 [==============================] - 4s 26us/sample - loss: 0.5790 - acc: 0.7073 - val_loss: 0.5955 - val_acc: 0.6923\n",
      "Epoch 9/40\n",
      "159997/159997 [==============================] - 4s 26us/sample - loss: 0.5743 - acc: 0.7098 - val_loss: 0.5938 - val_acc: 0.6937\n",
      "Epoch 10/40\n",
      "159997/159997 [==============================] - 4s 26us/sample - loss: 0.5703 - acc: 0.7122 - val_loss: 0.5929 - val_acc: 0.6945\n",
      "Epoch 11/40\n",
      "159997/159997 [==============================] - 4s 27us/sample - loss: 0.5666 - acc: 0.7142 - val_loss: 0.5924 - val_acc: 0.6944\n",
      "Epoch 12/40\n",
      "159997/159997 [==============================] - 6s 35us/sample - loss: 0.5636 - acc: 0.7157 - val_loss: 0.5926 - val_acc: 0.6934\n",
      "Epoch 13/40\n",
      "159997/159997 [==============================] - 6s 35us/sample - loss: 0.5610 - acc: 0.7175 - val_loss: 0.5930 - val_acc: 0.6943\n",
      "Epoch 14/40\n",
      "159997/159997 [==============================] - 5s 28us/sample - loss: 0.5587 - acc: 0.7190 - val_loss: 0.5927 - val_acc: 0.6949\n",
      "Epoch 15/40\n",
      "159997/159997 [==============================] - 5s 33us/sample - loss: 0.5566 - acc: 0.7204 - val_loss: 0.5935 - val_acc: 0.6936\n",
      "Epoch 16/40\n",
      "159997/159997 [==============================] - 4s 27us/sample - loss: 0.5548 - acc: 0.7216 - val_loss: 0.5926 - val_acc: 0.6945\n",
      "Epoch 17/40\n",
      "159997/159997 [==============================] - 4s 26us/sample - loss: 0.5531 - acc: 0.7228 - val_loss: 0.5929 - val_acc: 0.6932\n",
      "Epoch 18/40\n",
      "159997/159997 [==============================] - 4s 26us/sample - loss: 0.5519 - acc: 0.7237 - val_loss: 0.5938 - val_acc: 0.6929\n",
      "Epoch 19/40\n",
      "159997/159997 [==============================] - 5s 31us/sample - loss: 0.5504 - acc: 0.7244 - val_loss: 0.5943 - val_acc: 0.6926\n",
      "Epoch 20/40\n",
      "159997/159997 [==============================] - 4s 27us/sample - loss: 0.5494 - acc: 0.7253 - val_loss: 0.5945 - val_acc: 0.6924\n",
      "Epoch 21/40\n",
      "159997/159997 [==============================] - 4s 28us/sample - loss: 0.5484 - acc: 0.7256 - val_loss: 0.5959 - val_acc: 0.6916\n",
      "Epoch 22/40\n",
      "159997/159997 [==============================] - 4s 28us/sample - loss: 0.5473 - acc: 0.7258 - val_loss: 0.5951 - val_acc: 0.6926\n",
      "Epoch 23/40\n",
      "159997/159997 [==============================] - 5s 29us/sample - loss: 0.5466 - acc: 0.7262 - val_loss: 0.5959 - val_acc: 0.6912\n",
      "Epoch 24/40\n",
      "159997/159997 [==============================] - 5s 30us/sample - loss: 0.5457 - acc: 0.7270 - val_loss: 0.5969 - val_acc: 0.6909\n",
      "Epoch 25/40\n",
      "159997/159997 [==============================] - 5s 29us/sample - loss: 0.5450 - acc: 0.7277 - val_loss: 0.5972 - val_acc: 0.6911\n",
      "Epoch 26/40\n",
      "159997/159997 [==============================] - 4s 27us/sample - loss: 0.5443 - acc: 0.7280 - val_loss: 0.5975 - val_acc: 0.6908\n",
      "Epoch 27/40\n",
      "159997/159997 [==============================] - 5s 29us/sample - loss: 0.5439 - acc: 0.7278 - val_loss: 0.5979 - val_acc: 0.6911\n",
      "Epoch 28/40\n",
      "159997/159997 [==============================] - 4s 27us/sample - loss: 0.5433 - acc: 0.7286 - val_loss: 0.5988 - val_acc: 0.6907\n",
      "Epoch 29/40\n",
      "159997/159997 [==============================] - 4s 28us/sample - loss: 0.5425 - acc: 0.7288 - val_loss: 0.5987 - val_acc: 0.6904\n",
      "Epoch 30/40\n",
      "159997/159997 [==============================] - 5s 29us/sample - loss: 0.5420 - acc: 0.7283 - val_loss: 0.5994 - val_acc: 0.6896\n",
      "Epoch 31/40\n",
      "159997/159997 [==============================] - 4s 28us/sample - loss: 0.5416 - acc: 0.7288 - val_loss: 0.6004 - val_acc: 0.6902\n",
      "Epoch 32/40\n",
      "159997/159997 [==============================] - 5s 28us/sample - loss: 0.5410 - acc: 0.7301 - val_loss: 0.6004 - val_acc: 0.6899\n",
      "Epoch 33/40\n",
      "159997/159997 [==============================] - 5s 29us/sample - loss: 0.5406 - acc: 0.7295 - val_loss: 0.6009 - val_acc: 0.6903\n",
      "Epoch 34/40\n",
      "159997/159997 [==============================] - 5s 29us/sample - loss: 0.5405 - acc: 0.7298 - val_loss: 0.6021 - val_acc: 0.6871\n",
      "Epoch 35/40\n",
      "159997/159997 [==============================] - 4s 27us/sample - loss: 0.5399 - acc: 0.7302 - val_loss: 0.6017 - val_acc: 0.6889\n",
      "Epoch 36/40\n",
      "159997/159997 [==============================] - 4s 26us/sample - loss: 0.5394 - acc: 0.7304 - val_loss: 0.6018 - val_acc: 0.6891\n",
      "Epoch 37/40\n",
      "159997/159997 [==============================] - 5s 29us/sample - loss: 0.5391 - acc: 0.7311 - val_loss: 0.6028 - val_acc: 0.6888\n",
      "Epoch 38/40\n",
      "159997/159997 [==============================] - 5s 29us/sample - loss: 0.5388 - acc: 0.7305 - val_loss: 0.6025 - val_acc: 0.6891\n",
      "Epoch 39/40\n",
      "159997/159997 [==============================] - 4s 28us/sample - loss: 0.5383 - acc: 0.7309 - val_loss: 0.6032 - val_acc: 0.6887\n",
      "Epoch 40/40\n",
      "159997/159997 [==============================] - 5s 28us/sample - loss: 0.5379 - acc: 0.7315 - val_loss: 0.6042 - val_acc: 0.6880\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data,\n",
    "                    y_train,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(test_data, y_test),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2500020158329875"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = np.full(y_test.shape, y_train.mean())\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
